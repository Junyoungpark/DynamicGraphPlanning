{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11840dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pdb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "from env.sys_admin import *\n",
    "from gnn_model import GraphGNNModel\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/victorialena/rlkit')\n",
    "\n",
    "import rlkit\n",
    "# from rlkit.samplers.data_collector import MdpPathCollector\n",
    "from path_collector import MdpPathCollector\n",
    "from rlkit.torch.torch_rl_algorithm import TorchBatchRLAlgorithm\n",
    "\n",
    "from any_replay_buffer import anyReplayBuffer\n",
    "from dqn import DQNTrainer\n",
    "from policies import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d31cdc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = sysAdmin(nnodes=6, njobs=25)\n",
    "x = env.reset(topology='star')\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3490a63",
   "metadata": {},
   "source": [
    "```python\n",
    "a = env.action_space.sample()\n",
    "data, r, _, _ = env.step(a)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d680ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = len(load)+len(status)\n",
    "out_channels = len(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a97994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.cuda.current_device() if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0c9b163",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "from torch.nn import Linear, ReLU\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class sysAdminModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, c_in, c_out, c_hidden=64, dp_rate_linear=0.5, **kwargs):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(OrderedDict([\n",
    "            ('fc1', nn.Linear(in_channels, c_hidden)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('fc2', nn.Linear(c_hidden, out_channels)),\n",
    "#             ('relu2', nn.ReLU()),\n",
    "#             ('fc3', nn.Linear(c_hidden, out_channels)),\n",
    "            ('act', nn.Softmax(dim=1))\n",
    "        ]))\n",
    "\n",
    "        self._device = 'cpu'\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        return self.model(x.to(self._device))\n",
    "    \n",
    "    def to(self, device):\n",
    "        super().to(device)\n",
    "        self._device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b559111",
   "metadata": {},
   "outputs": [],
   "source": [
    "qf = sysAdminModel(in_channels, out_channels)\n",
    "target_qf = sysAdminModel(in_channels, out_channels)\n",
    "\n",
    "# qf = GraphGNNModel(in_channels, 256, out_channels, use_edge_weight=False)\n",
    "# target_qf = GraphGNNModel(in_channels, 256, out_channels, use_edge_weight=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8783bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rlkit.policies.base import Policy\n",
    "\n",
    "class sysRolloutPolicy(nn.Module, Policy):\n",
    "    def __init__(self, aspace, eps=0.05):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.aspace = aspace\n",
    "\n",
    "    def get_action(self, obs):\n",
    "        if rand() < self.eps:\n",
    "            return self.aspace.sample(), {}\n",
    "        return torch.where(obs.x[:, 0]==status.dead, action.reboot, action.noop).cpu().detach().numpy(), {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e35f8a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "qf_criterion = nn.MSELoss() #nn.CrossEntropyLoss() #nn.MSELoss()\n",
    "eval_policy = argmaxDiscretePolicy(qf, format_data)\n",
    "# expl_policy = sysRolloutPolicy(env.action_space)\n",
    "expl_policy = epsilonGreedyPolicy(qf, format_data, env.action_space, eps=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17899016",
   "metadata": {},
   "source": [
    "```python\n",
    "expl_policy = sysRolloutPolicy(env.action_space)\n",
    "expl_path_collector = MdpPathCollector(env, expl_policy)\n",
    "paths = expl_path_collector.collect_new_paths(1, 40, False)\n",
    "\n",
    "for s, a, r, t in zip(paths[0]['observations'], paths[0]['actions'], \n",
    "                      paths[0]['rewards'], paths[0]['terminals']):\n",
    "    print(s.x)\n",
    "    print(a)\n",
    "    print(r)\n",
    "    print(t)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bc349ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0960b137",
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_path_collector = MdpPathCollector(env, expl_policy)\n",
    "eval_path_collector = MdpPathCollector(env, eval_policy)\n",
    "replay_buffer = anyReplayBuffer(10000)\n",
    "optimizer = Adam(qf.parameters(), lr=1E-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2ebd51",
   "metadata": {},
   "source": [
    "#### Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04495e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  0  -> loss:  4.007802963256836 , rewards:  -1.44482421875\n",
      "iter  1  -> loss:  4.075602054595947 , rewards:  -1.47265625\n",
      "iter  2  -> loss:  4.034618854522705 , rewards:  -1.47265625\n",
      "iter  3  -> loss:  3.9768521785736084 , rewards:  -1.4599609375\n",
      "iter  4  -> loss:  3.896735429763794 , rewards:  -1.44921875\n",
      "iter  5  -> loss:  3.8800208568573 , rewards:  -1.45703125\n",
      "iter  6  -> loss:  3.8534107208251953 , rewards:  -1.458984375\n",
      "iter  7  -> loss:  3.374918222427368 , rewards:  -1.27880859375\n",
      "iter  8  -> loss:  3.005838632583618 , rewards:  -1.13427734375\n",
      "iter  9  -> loss:  2.6532323360443115 , rewards:  -0.99658203125\n",
      "iter  10  -> loss:  2.4861133098602295 , rewards:  -0.93359375\n",
      "iter  11  -> loss:  1.9483038187026978 , rewards:  -0.71044921875\n",
      "iter  12  -> loss:  1.7945648431777954 , rewards:  -0.642578125\n",
      "iter  13  -> loss:  1.277905821800232 , rewards:  -0.42724609375\n",
      "iter  14  -> loss:  1.2084096670150757 , rewards:  -0.39794921875\n",
      "iter  15  -> loss:  0.7195394039154053 , rewards:  -0.18798828125\n",
      "iter  16  -> loss:  0.37000954151153564 , rewards:  -0.03955078125\n",
      "iter  17  -> loss:  0.375887006521225 , rewards:  -0.04736328125\n",
      "iter  18  -> loss:  0.35280025005340576 , rewards:  -0.03515625\n",
      "iter  19  -> loss:  0.3687000274658203 , rewards:  -0.0439453125\n",
      "iter  20  -> loss:  0.3485553562641144 , rewards:  -0.0361328125\n",
      "iter  21  -> loss:  0.36167851090431213 , rewards:  -0.04443359375\n",
      "iter  22  -> loss:  0.34837841987609863 , rewards:  -0.03662109375\n",
      "iter  23  -> loss:  0.3484831750392914 , rewards:  -0.041015625\n",
      "iter  24  -> loss:  0.34885358810424805 , rewards:  -0.044921875\n",
      "iter  25  -> loss:  0.3154545724391937 , rewards:  -0.02880859375\n",
      "iter  26  -> loss:  0.31949976086616516 , rewards:  -0.03271484375\n",
      "iter  27  -> loss:  0.35133659839630127 , rewards:  -0.05029296875\n",
      "iter  28  -> loss:  0.32275307178497314 , rewards:  -0.03857421875\n",
      "iter  29  -> loss:  0.31724438071250916 , rewards:  -0.03759765625\n",
      "iter  30  -> loss:  0.5742763876914978 , rewards:  -0.14013671875\n",
      "iter  31  -> loss:  1.0396147966384888 , rewards:  -0.32763671875\n",
      "iter  32  -> loss:  1.2676881551742554 , rewards:  -0.4150390625\n",
      "iter  33  -> loss:  1.8844496011734009 , rewards:  -0.662109375\n",
      "iter  34  -> loss:  2.1412947177886963 , rewards:  -0.765625\n",
      "iter  35  -> loss:  2.536104917526245 , rewards:  -0.9267578125\n",
      "iter  36  -> loss:  2.433553695678711 , rewards:  -0.8916015625\n",
      "iter  37  -> loss:  2.4258899688720703 , rewards:  -0.89794921875\n",
      "iter  38  -> loss:  2.4283483028411865 , rewards:  -0.9033203125\n",
      "iter  39  -> loss:  2.490882396697998 , rewards:  -0.939453125\n",
      "iter  40  -> loss:  1.9894968271255493 , rewards:  -0.72802734375\n",
      "iter  41  -> loss:  1.6823512315750122 , rewards:  -0.60205078125\n",
      "iter  42  -> loss:  1.2537330389022827 , rewards:  -0.41552734375\n",
      "iter  43  -> loss:  1.0868085622787476 , rewards:  -0.34326171875\n",
      "iter  44  -> loss:  0.7338078618049622 , rewards:  -0.19140625\n",
      "iter  45  -> loss:  0.369858056306839 , rewards:  -0.03369140625\n",
      "iter  46  -> loss:  0.3762710392475128 , rewards:  -0.04052734375\n",
      "iter  47  -> loss:  0.3725241720676422 , rewards:  -0.04248046875\n",
      "iter  48  -> loss:  0.3542427122592926 , rewards:  -0.03466796875\n",
      "iter  49  -> loss:  0.3612876236438751 , rewards:  -0.041015625\n",
      "iter  50  -> loss:  0.36825552582740784 , rewards:  -0.0458984375\n",
      "iter  51  -> loss:  0.3253355026245117 , rewards:  -0.0283203125\n",
      "iter  52  -> loss:  0.3251676857471466 , rewards:  -0.02880859375\n",
      "iter  53  -> loss:  0.3357091248035431 , rewards:  -0.03955078125\n",
      "iter  54  -> loss:  0.3673841655254364 , rewards:  -0.0556640625\n",
      "iter  55  -> loss:  0.3344072103500366 , rewards:  -0.0419921875\n",
      "iter  56  -> loss:  0.3234091103076935 , rewards:  -0.0419921875\n",
      "iter  57  -> loss:  0.7023575901985168 , rewards:  -0.189453125\n",
      "iter  58  -> loss:  1.053242564201355 , rewards:  -0.32958984375\n",
      "iter  59  -> loss:  1.3889309167861938 , rewards:  -0.462890625\n",
      "iter  60  -> loss:  1.6863840818405151 , rewards:  -0.580078125\n",
      "iter  61  -> loss:  2.2253715991973877 , rewards:  -0.80126953125\n",
      "iter  62  -> loss:  1.9201430082321167 , rewards:  -0.6806640625\n",
      "iter  63  -> loss:  1.965031623840332 , rewards:  -0.70361328125\n",
      "iter  64  -> loss:  2.0325822830200195 , rewards:  -0.734375\n",
      "iter  65  -> loss:  2.0406577587127686 , rewards:  -0.744140625\n",
      "iter  66  -> loss:  2.0587666034698486 , rewards:  -0.7548828125\n",
      "iter  67  -> loss:  1.7625452280044556 , rewards:  -0.63232421875\n",
      "iter  68  -> loss:  1.2868971824645996 , rewards:  -0.43115234375\n",
      "iter  69  -> loss:  1.0960057973861694 , rewards:  -0.35205078125\n",
      "iter  70  -> loss:  0.7177338600158691 , rewards:  -0.1865234375\n",
      "iter  71  -> loss:  0.37281492352485657 , rewards:  -0.03857421875\n",
      "iter  72  -> loss:  0.381590873003006 , rewards:  -0.04541015625\n",
      "iter  73  -> loss:  0.3234633207321167 , rewards:  -0.01806640625\n",
      "iter  74  -> loss:  0.32525086402893066 , rewards:  -0.0234375\n",
      "iter  75  -> loss:  0.3464567959308624 , rewards:  -0.0361328125\n",
      "iter  76  -> loss:  0.33856895565986633 , rewards:  -0.03564453125\n",
      "iter  77  -> loss:  0.3469163477420807 , rewards:  -0.0439453125\n",
      "iter  78  -> loss:  0.3245052695274353 , rewards:  -0.03466796875\n",
      "iter  79  -> loss:  0.3162103593349457 , rewards:  -0.03515625\n",
      "iter  80  -> loss:  0.31596359610557556 , rewards:  -0.03515625\n",
      "iter  81  -> loss:  0.619870126247406 , rewards:  -0.15625\n",
      "iter  82  -> loss:  1.043654441833496 , rewards:  -0.326171875\n",
      "iter  83  -> loss:  1.3462409973144531 , rewards:  -0.4501953125\n",
      "iter  84  -> loss:  1.7239240407943726 , rewards:  -0.59814453125\n",
      "iter  85  -> loss:  2.139457941055298 , rewards:  -0.76513671875\n",
      "iter  86  -> loss:  2.475536346435547 , rewards:  -0.90625\n",
      "iter  87  -> loss:  2.458880662918091 , rewards:  -0.9091796875\n",
      "iter  88  -> loss:  2.4389119148254395 , rewards:  -0.90771484375\n",
      "iter  89  -> loss:  2.2957146167755127 , rewards:  -0.8603515625\n",
      "iter  90  -> loss:  2.1673176288604736 , rewards:  -0.81103515625\n",
      "iter  91  -> loss:  2.102195978164673 , rewards:  -0.7890625\n",
      "iter  92  -> loss:  1.6387308835983276 , rewards:  -0.58935546875\n",
      "iter  93  -> loss:  1.4364887475967407 , rewards:  -0.4990234375\n",
      "iter  94  -> loss:  1.1747939586639404 , rewards:  -0.38525390625\n",
      "iter  95  -> loss:  0.680223286151886 , rewards:  -0.16064453125\n",
      "iter  96  -> loss:  0.4062395989894867 , rewards:  -0.04296875\n",
      "iter  97  -> loss:  0.3719610869884491 , rewards:  -0.02685546875\n",
      "iter  98  -> loss:  0.38371530175209045 , rewards:  -0.0390625\n",
      "iter  99  -> loss:  0.36364832520484924 , rewards:  -0.03125\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    paths = expl_path_collector.collect_new_paths(1000, 40, False)\n",
    "    replay_buffer.add_paths(paths)\n",
    "    \n",
    "    qf.train(True)\n",
    "    loss = []\n",
    "    avg_r = []\n",
    "    for _ in range(10):\n",
    "        loss.clear()\n",
    "        avg_r.clear()\n",
    "        batch = replay_buffer.random_batch(512)\n",
    "        rewards = torch.Tensor(batch['rewards']).unsqueeze(-1)\n",
    "        terminals = torch.Tensor(batch['terminals'])\n",
    "        actions = torch.Tensor(batch['actions'])\n",
    "\n",
    "        obs = batch['observations']\n",
    "        next_obs = batch['next_observations']\n",
    "    \n",
    "        ff = lambda x: target_qf(*x)\n",
    "        out = torch.stack(list(map(ff, map(format_data, obs))), axis=0).cpu()\n",
    "        target_q_values = out.max(-1).values\n",
    "#         pdb.set_trace()\n",
    "        y_target = rewards + (1. - terminals) * 0.95 * target_q_values\n",
    "        \n",
    "        ff = lambda x: qf(*x)\n",
    "        out = torch.stack(list(map(ff, map(format_data, obs))), axis=0).cpu()\n",
    "        \n",
    "        actions_one_hot = F.one_hot(actions.to(torch.int64))\n",
    "        y_pred = torch.sum(out * actions_one_hot, dim=-1)#.sum(1, keepdim=True)\n",
    "        qf_loss = qf_criterion(y_pred, y_target)\n",
    "        \n",
    "        loss.append(qf_loss.item())\n",
    "        avg_r.append(rewards.mean().item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        qf_loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    target_qf.load_state_dict(qf.state_dict())\n",
    "    print(\"iter \", i, \" -> loss: \", np.mean(loss), \", rewards: \", np.mean(avg_r))        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf25159",
   "metadata": {},
   "source": [
    "#### Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70a1280",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    paths = expl_path_collector.collect_new_paths(100, 80, False)\n",
    "    replay_buffer.add_paths(paths)\n",
    "    \n",
    "    qf.train(True)\n",
    "    loss = []\n",
    "    for _ in range(50):\n",
    "        loss.clear()\n",
    "        batch = replay_buffer.random_batch(256)\n",
    "        rewards = torch.Tensor(batch['rewards']).unsqueeze(-1)\n",
    "        terminals = torch.Tensor(batch['terminals'])\n",
    "        actions = torch.Tensor(batch['actions'])\n",
    "\n",
    "        obs = batch['observations']\n",
    "        next_obs = batch['next_observations']\n",
    "    \n",
    "        ff = lambda x: qf(*x)\n",
    "        out = torch.stack(list(map(ff, map(format_data, obs))), axis=0).cpu()        \n",
    "        qf_loss = qf_criterion(out.swapaxes(1,2), actions.to(torch.int64))\n",
    "        \n",
    "        loss.append(qf_loss.item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        qf_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"iter \", i, \" -> loss: \", np.mean(loss))\n",
    "    \n",
    "    # test\n",
    "    # qf.train(False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00026d1f",
   "metadata": {},
   "source": [
    "```python\n",
    "paths = expl_path_collector.collect_new_paths(10, 20, False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f50f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant = dict(\n",
    "    algorithm=\"DQN\",\n",
    "    version=\"normal\",\n",
    "    layer_size=256,\n",
    "    replay_buffer_size=int(1E4),\n",
    "    algorithm_kwargs=dict(\n",
    "        num_epochs=300,\n",
    "        num_eval_steps_per_epoch=500,\n",
    "        num_trains_per_train_loop=100,\n",
    "        num_expl_steps_per_train_loop=100,\n",
    "        min_num_steps_before_training=100,\n",
    "        max_path_length=100,\n",
    "        batch_size=256,\n",
    "    ),\n",
    "    trainer_kwargs=dict(\n",
    "        discount=0.99,\n",
    "        learning_rate=1E-4,\n",
    "    ),\n",
    ")\n",
    "\n",
    "trainer = DQNTrainer(qf=qf,\n",
    "                     target_qf=target_qf,\n",
    "                     qf_criterion=qf_criterion,\n",
    "                     **variant['trainer_kwargs'],\n",
    "                     format_data = format_data)\n",
    "\n",
    "replay_buffer = anyReplayBuffer(variant['replay_buffer_size'])\n",
    "\n",
    "algorithm = TorchBatchRLAlgorithm(\n",
    "    trainer=trainer,\n",
    "    exploration_env=env,\n",
    "    evaluation_env=env,\n",
    "    exploration_data_collector=expl_path_collector,\n",
    "    evaluation_data_collector=eval_path_collector,\n",
    "    replay_buffer=replay_buffer,\n",
    "    **variant['algorithm_kwargs']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73509958",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm.to(device)\n",
    "# algorithm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed66e63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be477426",
   "metadata": {},
   "source": [
    "### Notes\n",
    "1. Instead of a GCN use a normal GNN\n",
    "2. add self loops\n",
    "3. try over fitting a linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1d5f65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rlpyt] *",
   "language": "python",
   "name": "conda-env-rlpyt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
